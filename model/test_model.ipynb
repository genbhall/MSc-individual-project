{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from orion import Orion\n",
    "from orion.evaluation.contextual import contextual_accuracy, contextual_f1_score, contextual_precision\n",
    "import pandas as pd\n",
    "from output_utils.utils import plot\n",
    "from supporting_func.supporting_func import split_data, save_model, load_model, print_anomalies, convert_dfdatetotime, convert_dftimetodate\n",
    "from global_variables.global_variables import filename_train, all_activities, filename_test, filename_summary\n",
    "from orion.primitives.tadgan import TadGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    pickle_file = \"sleep_model.pickle\"\n",
    "\n",
    "    # df = pd.read_csv(filename_train)\n",
    "    # dict_dfs = split_data(df,30)\n",
    "    # training_df = dict_dfs[0][all_activities]\n",
    "    # test_df = dict_dfs[1][all_activities]\n",
    "\n",
    "    # test_df = test_df[all_activities]\n",
    "    # parameters = {\n",
    "    #     \"mlprimitives.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n",
    "    #         \"interval\": 300 # 5min\n",
    "    #     },\n",
    "    #     'orion.primitives.tadgan.TadGAN#1': {\n",
    "    #         'epochs': 30,\n",
    "    #         'latent_dim': 50,\n",
    "    #         'dense_units': 50,\n",
    "    #     }\n",
    "    # }\n",
    "    # orion = Orion(pipeline='config/tadgan.json', hyperparameters=parameters)\n",
    "    # orion.fit(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # load and read files - detect anomalies\n",
    "    # df = pd.read_csv(filename_test)\n",
    "    # df = df[all_activities]\n",
    "    # orion = load_model(pickle_file)\n",
    "    # # print(dir(orion._mlpipeline.predict))\n",
    "    # prediction,  = orion._mlpipeline.predict(df)\n",
    "    # print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    df = pd.read_csv(filename_train)\n",
    "    df = df[all_activities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mlprimitives.custom.timeseries_preprocessing.time_segments_aggregate', 'sklearn.impute.SimpleImputer', 'sklearn.preprocessing.MinMaxScaler', 'mlprimitives.custom.timeseries_preprocessing.rolling_window_sequences', 'orion.primitives.timeseries_preprocessing.slice_array_by_dims', 'orion.primitives.tadgan.TadGAN', 'orion.primitives.tadgan.score_anomalies', 'orion.primitives.timeseries_anomalies.find_anomalies']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#importing sklearn module\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#utils.py contains all the plot function.\n",
    "# from utils import plot, plot_ts, plot_rws, plot_error, unroll_ts\n",
    "\n",
    "with open(\"config/tadgan.json\") as f:\n",
    "  primitives = json.load(f)[\"primitives\"]\n",
    "print(primitives) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_segments_aggregate(X, interval, time_column, method=['mean']):\n",
    "    \"\"\"Aggregate values over given time span.\n",
    "    Args:\n",
    "        X (ndarray or pandas.DataFrame):\n",
    "            N-dimensional sequence of values.\n",
    "        interval (int):\n",
    "            Integer denoting time span to compute aggregation of.\n",
    "        time_column (int):\n",
    "            Column of X that contains time values.\n",
    "        method (str or list):\n",
    "            Optional. String describing aggregation method or list of strings describing multiple\n",
    "            aggregation methods. If not given, `mean` is used.\n",
    "    Returns:\n",
    "        ndarray, ndarray:\n",
    "            * Sequence of aggregated values, one column for each aggregation method.\n",
    "            * Sequence of index values (first index of each aggregated segment).\n",
    "    \"\"\"\n",
    "    #checking for the input datatype as numpy array and converting it to dataframe\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "    #sorting the values on timestamp column and setting it as a index\n",
    "    X = X.sort_values(time_column).set_index(time_column)\n",
    "\n",
    "    if isinstance(method, str):\n",
    "        method = [method]\n",
    "\n",
    "    start_ts = X.index.values[0]\n",
    "    max_ts = X.index.values[-1]\n",
    "\n",
    "    values = list()\n",
    "    index = list()\n",
    "    while start_ts <= max_ts:\n",
    "        end_ts = start_ts + interval\n",
    "        subset = X.loc[start_ts:end_ts - 1]\n",
    "        aggregated = [\n",
    "            getattr(subset, agg)(skipna=True).values\n",
    "            for agg in method\n",
    "        ]\n",
    "        values.append(np.concatenate(aggregated))\n",
    "        index.append(start_ts)\n",
    "        start_ts = end_ts\n",
    "\n",
    "    return np.asarray(values), np.asarray(index)\n",
    "#here df is the given dataframe and \"timestamp\" is the required column to be altered.\n",
    "X, index = time_segments_aggregate(df, interval=60, time_column='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the simple scikit imputer\n",
    "imp = SimpleImputer()\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_sequences(X, index, window_size, target_size, step_size, target_column,\n",
    "                             drop=None, drop_windows=False):\n",
    "    \"\"\"Create rolling window sequences out of time series data.\n",
    "    The function creates an array of input sequences and an array of target sequences by rolling\n",
    "    over the input sequence with a specified window.\n",
    "    Optionally, certain values can be dropped from the sequences.\n",
    "    Args:\n",
    "        X (ndarray):\n",
    "            N-dimensional sequence to iterate over.\n",
    "        index (ndarray):\n",
    "            Array containing the index values of X.\n",
    "        window_size (int):\n",
    "            Length of the input sequences.\n",
    "        target_size (int):\n",
    "            Length of the target sequences.\n",
    "        step_size (int):\n",
    "            Indicating the number of steps to move the window forward each round.\n",
    "        target_column (int):\n",
    "            Indicating which column of X is the target.\n",
    "        drop (ndarray or None or str or float or bool):\n",
    "            Optional. Array of boolean values indicating which values of X are invalid, or value\n",
    "            indicating which value should be dropped. If not given, `None` is used.\n",
    "        drop_windows (bool):\n",
    "            Optional. Indicates whether the dropping functionality should be enabled. If not\n",
    "            given, `False` is used.\n",
    "    Returns:\n",
    "        ndarray, ndarray, ndarray, ndarray:\n",
    "            * input sequences.\n",
    "            * target sequences.\n",
    "            * first index value of each input sequence.\n",
    "            * first index value of each target sequence.\n",
    "    \"\"\"\n",
    "    out_X = list()\n",
    "    out_y = list()\n",
    "    X_index = list()\n",
    "    y_index = list()\n",
    "    target = X[:, target_column]\n",
    "\n",
    "    if drop_windows:\n",
    "        if hasattr(drop, '__len__') and (not isinstance(drop, str)):\n",
    "            if len(drop) != len(X):\n",
    "                raise Exception('Arrays `drop` and `X` must be of the same length.')\n",
    "        else:\n",
    "            if isinstance(drop, float) and np.isnan(drop):\n",
    "                drop = np.isnan(X)\n",
    "            else:\n",
    "                drop = X == drop\n",
    "\n",
    "    start = 0\n",
    "    max_start = len(X) - window_size - target_size + 1\n",
    "    while start < max_start:\n",
    "        end = start + window_size\n",
    "\n",
    "        if drop_windows:\n",
    "            drop_window = drop[start:end + target_size]\n",
    "            to_drop = np.where(drop_window)[0]\n",
    "            if to_drop.size:\n",
    "                start += to_drop[-1] + 1\n",
    "                continue\n",
    "\n",
    "        out_X.append(X[start:end])\n",
    "        out_y.append(target[end:end + target_size])\n",
    "        X_index.append(index[start])\n",
    "        y_index.append(index[end])\n",
    "        start = start + step_size\n",
    "\n",
    "    return np.asarray(out_X), np.asarray(out_y), np.asarray(X_index), np.asarray(y_index)\n",
    "#the target value; the value at time t.\n",
    "#previous observed values, this is determined by the window width.\n",
    "X, y, X_index, y_index = rolling_window_sequences(X, index, \n",
    "                                                  window_size=100, \n",
    "                                                  target_size=1, \n",
    "                                                  step_size=1,\n",
    "                                                  target_column=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data input shape: (85652, 100, 1)\n",
      "Training data index shape: (85652,)\n",
      "Training y shape: (85652, 1)\n",
      "Training y index shape: (85652,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data input shape: {}\".format(X.shape))\n",
    "print(\"Training data index shape: {}\".format(X_index.shape))\n",
    "print(\"Training y shape: {}\".format(y.shape))\n",
    "print(\"Training y index shape: {}\".format(y_index.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from output_utils.utils import plot, plot_ts, plot_rws, plot_error, unroll_ts\n",
    "#function from utils.py module. Representing all the windows that has been created by slicing\n",
    "#Here X represents the input used to train the model. In the previous example, we see X has 10222 training data points.\n",
    "#Notice that 100 represents the window size. On the other hand, y is the real signal after processing, \n",
    "#which we will use later on to calculate the error between the reconstructed and real signal.\n",
    "plot_rws(X, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hall/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/hall/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hall/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "2022-08-05 16:27:36.994395: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-08-05 16:27:37.027676: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2009cf780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-05 16:27:37.027692: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hall/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hall/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/Users/hall/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "2022-08-05 16:27:54.716701: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\n",
      "2022-08-05 16:27:54.750785: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\n",
      "2022-08-05 16:27:54.863563: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] model_pruner failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss_2/model_2_loss/mean_squared_error/weighted_loss/concat' has self cycle fanin 'loss_2/model_2_loss/mean_squared_error/weighted_loss/concat'.\n",
      "2022-08-05 16:27:55.133842: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss_2/model_2_loss/mean_squared_error/weighted_loss/concat' has self cycle fanin 'loss_2/model_2_loss/mean_squared_error/weighted_loss/concat'.\n",
      "2022-08-05 16:27:55.181498: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.\n",
      "2022-08-05 16:27:55.214469: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\n",
      "2022-08-05 16:27:55.247564: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\n",
      "/Users/hall/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/35, [Dx loss: [-0.98563564 -5.08036     3.6146421   0.04800872]] [Dz loss: [-2.5989091  -1.2736619  -1.9597181   0.06344667]] [G loss: [ 0.44746172 -3.5276089   2.3249023   0.16501714]]\n",
      "Epoch: 2/35, [Dx loss: [-0.48200518  1.894649   -2.5538104   0.01771569]] [Dz loss: [-2.6180804  -2.868402   -0.1689893   0.04193065]] [G loss: [3.7489605  2.740942   0.27098396 0.07370348]]\n",
      "Epoch: 3/35, [Dx loss: [-3.4991392e-01  2.2796377e+01 -2.3292580e+01  1.4630787e-02]] [Dz loss: [-2.7293963 -4.4009404  1.2193145  0.0452229]] [G loss: [22.892385   23.267712   -1.1250259   0.07497016]]\n",
      "Epoch: 4/35, [Dx loss: [-2.8974390e-01  1.5184445e+01 -1.5618404e+01  1.4421750e-02]] [Dz loss: [-2.9156697  -4.9479375   1.5877913   0.04444763]] [G loss: [14.687216   15.5493     -1.525534    0.06634425]]\n",
      "Epoch: 5/35, [Dx loss: [-0.24434488 -1.8967428   1.5281379   0.01242481]] [Dz loss: [-2.9181938  -5.076551    1.7210352   0.04373254]] [G loss: [-2.4120412  -1.3829229  -1.6552887   0.06261647]]\n",
      "Epoch: 6/35, [Dx loss: [-0.23521401  1.4067118  -1.7606877   0.01187667]] [Dz loss: [-2.8903346  -4.9560366   1.6237332   0.04419673]] [G loss: [ 0.8343102   1.729913   -1.549851    0.06542522]]\n",
      "Epoch: 7/35, [Dx loss: [-7.9795226e-02 -2.3842470e+01  2.3647326e+01  1.1532485e-02]] [Dz loss: [-2.8958015  -5.5919075   2.252795    0.04433149]] [G loss: [-25.026123   -23.512093    -2.176489     0.06624629]]\n",
      "Epoch: 8/35, [Dx loss: [-0.28389263 -1.7300626   1.3290474   0.011712  ]] [Dz loss: [-2.847608   -5.4960403   2.206622    0.04418118]] [G loss: [-2.9908412  -1.4626935  -2.1357021   0.06075543]]\n",
      "Epoch: 9/35, [Dx loss: [-1.06682405e-02  3.14514313e+01 -3.15700665e+01  1.07912375e-02]] [Dz loss: [-2.7519207  -5.4544463   2.258875    0.04436438]] [G loss: [29.988781   31.591064   -2.1831346   0.05808336]]\n",
      "Epoch: 10/35, [Dx loss: [-8.33009407e-02  1.01815605e+01 -1.03664150e+01  1.01547670e-02]] [Dz loss: [-2.6289978  -3.3487172   0.22364064  0.04960771]] [G loss: [11.093309   10.184896   -0.07767082  0.09860808]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9y/cqpkls2x1qv2_l19_9thsdxc0000gn/T/ipykernel_29352/3767646414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTadGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/orion/primitives/tadgan.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_tadgan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/orion/primitives/tadgan.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, target)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 epoch_g_loss.append(\n\u001b[0;32m--> 269\u001b[0;31m                     self.encoder_generator_model.train_on_batch([x, z], [valid, valid, y]))\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mcx_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_cx_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/Dropbox/Imperial/Individual-project/individual-project/.venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from config.model import hyperparameters\n",
    "from orion.primitives.tadgan import TadGAN\n",
    "\n",
    "hyperparameters[\"epochs\"] = 35\n",
    "hyperparameters[\"shape\"] = (100, 1) # based on the window size\n",
    "hyperparameters[\"optimizer\"] = \"keras.optimizers.Adam\"\n",
    "hyperparameters[\"learning_rate\"] = 0.0005\n",
    "hyperparameters[\"latent_dim\"] = 20\n",
    "hyperparameters[\"batch_size\"] = 64\n",
    "\n",
    "tgan = TadGAN(**hyperparameters)\n",
    "tgan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructing the signal\n",
    "X_hat, critic = tgan.predict(X)\n",
    "# visualize X_hat\n",
    "plot_rws(X_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the predicted windows \n",
    "y_hat = unroll_ts(X_hat)\n",
    "# plot the time series data \n",
    "plot_ts([y, y_hat], labels=['original', 'reconstructed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair-wise error calculation\n",
    "error = np.zeros(shape=y.shape)\n",
    "length = y.shape[0]\n",
    "for i in range(length):\n",
    "    error[i] = abs(y_hat[i] - y[i])\n",
    "\n",
    "# visualize the error curve\n",
    "fig = plt.figure(figsize=(30, 3))\n",
    "plt.plot(error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion.primitives.tadgan import score_anomalies\n",
    "error, true_index, true, pred = score_anomalies(X, X_hat, critic, X_index, rec_error_type=\"dtw\", comb=\"mult\")\n",
    "pred = np.array(pred).mean(axis=2)\n",
    "# visualize the error curve\n",
    "plot_error([[true, pred], error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold to classify the high peak data points as anomolous points\n",
    "thresh = 5\n",
    "\n",
    "intervals = list()\n",
    "\n",
    "i = 0\n",
    "max_start = len(error)\n",
    "while i < max_start:\n",
    "    j = i\n",
    "    start = index[i]\n",
    "    while error[i] > thresh:\n",
    "        i += 1\n",
    "    \n",
    "    end = index[i]\n",
    "    if start != end:\n",
    "        intervals.append((start, end, np.mean(error[j: i+1])))\n",
    "        \n",
    "    i += 1\n",
    "        \n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = pd.DataFrame(intervals, columns=['start', 'end', 'score'])\n",
    "#now plotting the actual data, known anomalies and predicted anomalies\n",
    "plot(df, [anomalies])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ba2c3715a8b05982243bcb9c498950520be78d172a48bb945a11318acef9b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
